# Copilot Instructions

## TDD Methodology

### RED Phase (Failing Tests)
- **Always start with a failing test** - Write the test first, before any implementation
- **Make the test specific and focused** - Test one behavior at a time
- **Use descriptive test names** that clearly state the expected behavior
- **Write the minimum test code** needed to express the requirement
- **Do NOT write any production code or suggest implementation** 
- **Do NOT write additional tests beyond this one scenario**
- **Ensure the test fails for the right reason** - Run it to verify it fails as expected
- **Use `prop_assume!` in property-based tests** to filter invalid inputs
- **Include clear assertion messages** that explain what went wrong
- **Never proceed to the GREEN phase without permission**

### GREEN Phase (Minimal Implementation)
- **Write the minimum code** needed to make the test pass
- **Don't worry about perfect design** - focus on making tests pass
- **Use the simplest solution** that works, even if it seems naive
- **Avoid premature optimization** - get to green first
- **Hard-code values if necessary** - refactoring comes later
- **Run tests frequently** to ensure you're making progress
- **Stop as soon as tests pass** - don't add extra functionality
- **Don't refactor the tests** - just implement the code
- **Never proceed to the REFACTOR phase without permission**

### REFACTOR Phase (Improve Design)
- **Only refactor when tests are green** - never refactor failing code
- **Improve code structure** without changing behavior
- **Extract functions, methods, and constants** to improve readability
- **Remove duplication** (DRY principle)
- **Improve variable and function names** for clarity
- **Run tests after each refactoring step** to ensure behavior is preserved
- **Consider performance optimizations** only after the design is clean
- **Don't refactor the tests** - suggest improvements in case
- **Always lint and format at the end** - run `cargo clippy -- -D warnings` and `cargo fmt`
- **Fix all clippy warnings** before considering refactor phase complete

## Code Quality Guidelines

### Before Creating New Code
- **Search existing codebase** for similar functionality before implementing
- **Reuse established functions and patterns** rather than duplicating logic
- **Check imports and exports** to see what's already available
- **Use existing type aliases and data structures** consistently
- **Leverage established infrastructure** (e.g., `count_byte_frequencies`, `build_huffman_tree`)

### Documentation and Comments
- **Keep code self-explanatory** - prefer clear naming over comments
- **Avoid obvious comments** that just restate what the code does
- **Only add comments for complex algorithms** or non-obvious business logic
- **Use doc comments (///)** sparingly, mainly for public APIs
- **Prefer descriptive function and variable names** over explanatory comments
- **Let tests serve as documentation** for expected behavior

### Property-Based Testing
- **Use proptest for comprehensive validation** of algorithm properties
- **Generate realistic input data** that matches actual usage patterns
- **Test mathematical properties** (e.g., prefix-free codes, frequency relationships)
- **Include edge cases** in property test assumptions
- **Use helper functions** to reduce duplication in property tests

### Rust Best Practices
- **Use type aliases** for complex types (e.g., `ByteFrequencyMap`)
- **Implement appropriate traits** (`Ord`, `PartialOrd`, `Eq`) for custom types
- **Prefer functional programming patterns** with iterators and method chaining
- **Use `HashMap` and `BinaryHeap`** for appropriate data structures
- **Handle errors appropriately** with `Result` and `Option`
- **Keep functions focused** on single responsibilities

### Test Organization
- **Group related tests** in separate files (e.g., `frequency_map_tests.rs`)
- **Use descriptive test module names** with `#[cfg(test)]`
- **Write unit tests** for individual functions
- **Write integration tests** for complete workflows
- **Use property-based tests** for mathematical properties
- **Avoid redundant tests** - remove overlapping test coverage

### Code Structure
- **Keep modules focused**: frequency_map, tree_construction, code_extraction
- **Export public APIs** through `lib.rs`
- **Use established type aliases** consistently across modules
- **Maintain clean separation** between test and production code

### Implementation and Test Separation
- **NEVER put implementation code in test files** - Always separate implementation from tests
- **Implementation goes in `src/` modules** - Create dedicated modules for all functionality
- **Unit tests go in `tests/unit/` directory** - Use `tests/unit/` for individual function and module tests
- **Property-based tests go in `tests/property/` directory** - Use `tests/property/` for proptest-based comprehensive validation
- **Tests import from the library** - Use `use tdd_huffman::{function_name, Type};`
- **Add modules to `lib.rs`** - Export new modules and functions for external use
- **Configure test files in `Cargo.toml`** - Add `[[test]]` entries for proper test discovery
- **Implementation must be reusable** - Code in `src/` can be used by other modules or external consumers
- **Tests focus on behavior verification** - No implementation details should be in test files
- **Follow established patterns** - Look at existing modules like `tree_construction.rs` and `tree_construction_tests.rs`

### Project Structure
- **NEVER create examples directory** - Do not create `examples/` folder or any example files
- **No example files in any location** - Avoid creating any files that demonstrate usage through examples
- **Tests serve as documentation** - Use comprehensive tests to show how the code should be used
- **Keep project structure clean** - Only include essential directories: `src/`, `tests/`, `scripts/`, `.github/`
